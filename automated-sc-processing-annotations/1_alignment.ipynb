{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tabula_sapiens/lib/python3.6/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import scanpy\n",
    "import os\n",
    "import argparse\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.dataset import AnnDatasetFromAnnData\n",
    "from scvi.models import VAE\n",
    "import torch\n",
    "import scanorama\n",
    "\n",
    "# default scVI training parameters\n",
    "use_cuda = True\n",
    "retrain = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'data/adata_small_test.h5ad'\n",
    "output_file_path = 'data/adata_small_test_output.h5ad'\n",
    "\n",
    "batch='batch'\n",
    "tissue='all'\n",
    "n_neighbors=25\n",
    "n_pcs=20\n",
    "cluster_resolution=5\n",
    "\n",
    "\n",
    "### pick a batch correction method\n",
    "\n",
    "# batch_correction = 'scVI'\n",
    "batch_correction ='bbknn'\n",
    "# batch_correction = 'scanorama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsetting sapiens data\n"
     ]
    }
   ],
   "source": [
    "print(\"subsetting sapiens data\")\n",
    "sapiens = sc.read_h5ad(\"data/OnClass_data/data_used_for_training/tabula-muris-senis-facs_cell_ontology.h5ad\")\n",
    "# if tissue != 'all':\n",
    "#     try:\n",
    "#         sapiens = sapiens[sapiens.obs['tissue'] == tissue].copy()\n",
    "\n",
    "print('reading data in')\n",
    "adata = sc.read_h5ad(input_file_path)\n",
    "print(adata)\n",
    "# adata.X = adata.raw.X\n",
    "adata = adata.concatenate(sapiens)\n",
    "print(adata)\n",
    "\n",
    "if batch_correction == 'bbknn':\n",
    "    print('normalization & scaling')\n",
    "    sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "    adata = sc.pp.filter_genes_dispersion(adata, subset=False, min_disp=.5, max_disp=None,\n",
    "                                          min_mean=.0125, max_mean=10, n_bins=20, n_top_genes=None,\n",
    "                                          log=True, copy=True)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.scale(adata, max_value=10, zero_center=False)\n",
    "    # adata.uns['tissue_colors'] = list(tissue_color_dict.values())\n",
    "\n",
    "    print('pca')\n",
    "    sc.tl.pca(adata, svd_solver='arpack')\n",
    "    sc.pl.pca_overview(adata)\n",
    "\n",
    "    print('neighs')\n",
    "    # sc.pp.neighbors(adata)\n",
    "    sc.external.pp.bbknn(adata,metric = 'euclidean',\n",
    "                          batch_key=batch,\n",
    "                          approx=True,\n",
    "                          n_pcs=n_pcs, trim=None, n_trees=10,\n",
    "                          use_faiss=True, set_op_mix_ratio=1.0, local_connectivity=1)\n",
    "\n",
    "    print('umap computing')\n",
    "    sc.tl.umap(adata, n_components=2)\n",
    "\n",
    "    print('clustering')\n",
    "    sc.tl.louvain(adata, resolution=cluster_resolution)\n",
    "    sc.tl.leiden(adata, resolution=cluster_resolution)\n",
    "\n",
    "    print('save h5ad and launch cellxgene')\n",
    "    adata.write(output_file_path + \"bbknn.h5ad\")\n",
    "\n",
    "if batch_correction == 'scVI':\n",
    "    model_file = output_file_path + 'scVI.model.pkl'\n",
    "    print('Define scVI Model')\n",
    "    data = AnnDatasetFromAnnData(adata, batch_label='batch')\n",
    "    vae = VAE(data.nb_genes, n_batch=data.n_batches,\n",
    "              n_layers=3, n_latent=50, dispersion='gene-batch',\n",
    "              reconstruction_loss='zinb')\n",
    "    trainer = UnsupervisedTrainer(\n",
    "        vae,\n",
    "        data,\n",
    "        train_size=0.99,\n",
    "        use_cuda=use_cuda,\n",
    "        frequency=5,\n",
    "        data_loader_kwargs={\"pin_memory\": False},\n",
    "        n_epochs_kl_warmup=10\n",
    "    )\n",
    "    print('train scVI')\n",
    "    if retrain:\n",
    "        trainer.train(n_epochs=1)\n",
    "        torch.save(trainer.model.state_dict(), model_file)\n",
    "    else:\n",
    "        if os.path.isfile(model_file):\n",
    "            trainer.model.load_state_dict(torch.load(model_file))\n",
    "            trainer.model.eval()\n",
    "        else:\n",
    "            trainer.train(n_epochs=1)\n",
    "            torch.save(trainer.model.state_dict(), model_file)\n",
    "\n",
    "    posterior = trainer.create_posterior(\n",
    "        trainer.model, data, indices=np.arange(len(data))\n",
    "    ).sequential()\n",
    "    latent = posterior.get_latent()\n",
    "    adata.obsm['X_scvi'] = latent[0]\n",
    "    print('umap computing')\n",
    "    sc.pp.neighbors(adata, n_neighbors=100, n_pcs=30, use_rep=\"X_scvi\")\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "    print('clustering')\n",
    "    sc.tl.louvain(adata, resolution=cluster_resolution)\n",
    "    sc.tl.leiden(adata, resolution=cluster_resolution)\n",
    "\n",
    "    print('save h5ad and launch cellxgene')\n",
    "    adata.write(output_file_path + \"scVI.h5ad\")\n",
    "\n",
    "if batch_correction == 'scanorama':\n",
    "    print('normalization & scaling & gene selection')\n",
    "    sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "    sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, batch_key=batch)\n",
    "    var_select = adata.var.highly_variable_nbatches > 1\n",
    "    var_genes = var_select.index[var_select]\n",
    "\n",
    "    adatas = [adata[adata.obs[batch] == i, var_genes] for i in np.unique(adata.obs[batch])]\n",
    "    integrated = scanorama.integrate_scanpy(adatas, dimred=50)\n",
    "    integrated = np.concatenate(integrated)\n",
    "    adata.obsm['X_scanorama'] = integrated\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    print('umap computing')\n",
    "    sc.pp.neighbors(adata, n_neighbors=100, n_pcs=50, use_rep=\"X_scanorama\")\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "    print('clustering')\n",
    "    sc.tl.louvain(adata, resolution=cluster_resolution)\n",
    "    sc.tl.leiden(adata, resolution=cluster_resolution)\n",
    "\n",
    "    print('save h5ad and launch cellxgene')\n",
    "    adata.write(output_file_path + \"scanorama.h5ad\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
