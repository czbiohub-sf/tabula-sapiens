{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyaK-TtD8kGE"
   },
   "source": [
    "# Using Tabula Sapiens as a reference for annotating new datasets\n",
    "This notebook allows you to annotate your data with a number of annotation methods using the Tabula Sapiens dataset as the reference. \n",
    "\n",
    "This notebook is also available as a [Google Colab notebook](https://colab.research.google.com/drive/1KEsTbySmXtnOeQo4lJu8OGtPQjHRs1R4#scrollTo=ObY9kyf7exOx)\n",
    "\n",
    "Integration Methods Provided:\n",
    "- scVI\n",
    "- bbKNN\n",
    "- scanorama\n",
    "\n",
    "Annotation Methods:\n",
    "- KNN on integrated spaces\n",
    "- scANVI\n",
    "- onClass\n",
    "- SVM\n",
    "- RandomForest\n",
    "\n",
    "**User action is only required in Step 2 and Step 3.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Setup Environment \n",
    "No user input required here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import anndata\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load your data\n",
    "\n",
    "Load your data into query_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seSJxbG0DaAv",
    "outputId": "279ad151-8948-4de7-bb57-4d06ff5510f1"
   },
   "outputs": [],
   "source": [
    "# Read in your data with the following command\n",
    "query_adata = anndata.read(\"data/LCA_raw.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 75071 × 23681\n",
       "    obs: 'cell_id', 'method', 'donor', 'cell_ontology_type', 'donor_method', 'cell_ontology_id'\n",
       "    var: 'feature_types.0.0-0', 'n_cells.0.0-0', 'gene_symbol.0.0-0', 'n_cells.1.0-0', 'n_cells.0-0', 'n_cells.1.1-0', 'feature_types.0.0.0.1-0', 'gene_symbol.0.0.0.1-0', 'n_cells.1.0.0.1-0', 'n_cells.1.0.1-0', 'n_cells-0', 'len-0', 'ensembl_id-0', 'contamination_prop-0-0', 'contamination_prop-1-0', 'contamination_prop-10-0', 'contamination_prop-11-0', 'contamination_prop-12-0', 'contamination_prop-13-0', 'contamination_prop-14-0', 'contamination_prop-2-0', 'contamination_prop-3-0', 'contamination_prop-4-0', 'contamination_prop-5-0', 'contamination_prop-6-0', 'contamination_prop-7-0', 'contamination_prop-8-0', 'contamination_prop-9-0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLyMH7PEpTyk"
   },
   "source": [
    "# Step 3: Setting Up Annotation Parameters (User Action Required)\n",
    "\n",
    "Here is where you set the parameters for the automated annotation.\n",
    "\n",
    "Arguments:\n",
    "- **tissue:** Tabula Sapiens tissue to annotate your data with. Available tissues: [\"Bladder\", \"Blood\", \"Bone_Marrow\", \"Kidney\", \"Large_Intestine\", \"Lung\",\"Lymph_Node\", \"Pancreas\", \"Small_Intestine\", \"Spleen\", \"Thymus\",\"Trachea\", \"Vasculature\"]\n",
    "- **save_location:** location to save results to. By default will save to a folder named `annotation_results`. \n",
    "- **query_batch_key:** key in `query_adata.obs` for batch correction. Set to None for no batch correction. \n",
    "- **methods:** these are the methods to run. By default, will run all methods.\n",
    "- **training_mode** can be `online` or `offline`. If `offline` will train scVI and scANVI models from scratch. If `online`, will use pretrained models.\n",
    "- **query_layers_key**: Key in `query_adata.layers` for count data.\n",
    "\n",
    "Lesser used parameters\n",
    "- **query_labels_key**: scANVI has the option to use labeled cells in the query dataset during training. To use some prelabeled cells from the query dataset, set `query_labels_key` to the corresponding key in `query_adata.obs`\n",
    "- **unknown_celltype_label**: If `query_labels_key` is not None, will treat everything not labeled `unknown_celltype_label` as a labeled cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2ylgWqDBtbWO"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "tissue options: \n",
    "[\"Bladder\", \"Blood\", \"Bone_Marrow\", \"Kidney\", \"Large_Intestine\", \"Lung\",\n",
    " \"Lymph_Node\", \"Pancreas\", \"Small_Intestine\", \"Spleen\", \"Thymus\",\n",
    " \"Trachea\", \"Vasculature\"]\n",
    "\"\"\"\n",
    "tissue = 'Lung'\n",
    "save_folder = 'data/docker_container_test'\n",
    "query_batch_key = 'method'\n",
    "methods = ['bbknn','scvi', 'scanvi', 'svm', 'rf', 'onclass', 'scanorama']\n",
    "training_mode='offline'\n",
    "query_layers_key=None\n",
    "\n",
    "\n",
    "# Lesser used parameters\n",
    "query_labels_key=None\n",
    "unknown_celltype_label='unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Downloading Reference Data and Pretrained Models\n",
    "No more user input required! Just run all the following code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITnCd0XJsNZk",
    "outputId": "eede628d-025c-4810-bfe7-c914681ca4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-07 02:34:26--  https://ndownloader.figshare.com/files/27388832\n",
      "Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 52.48.216.177, 18.200.61.225, 34.247.134.83, ...\n",
      "Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|52.48.216.177|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2673660872 (2.5G) [application/octet-stream]\n",
      "Saving to: ‘data/TS_Lung.h5ad’\n",
      "\n",
      "data/TS_Lung.h5ad   100%[===================>]   2.49G  18.5MB/s    in 2m 18s  \n",
      "\n",
      "2021-05-07 02:36:45 (18.5 MB/s) - ‘data/TS_Lung.h5ad’ saved [2673660872/2673660872]\n",
      "\n",
      "--2021-05-07 02:36:46--  https://www.dropbox.com/s/e4al4ia9hm9qtcg/Lung.tar.gz?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.18, 2620:100:601a:18::a27d:712\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/e4al4ia9hm9qtcg/Lung.tar.gz [following]\n",
      "--2021-05-07 02:36:46--  https://www.dropbox.com/s/dl/e4al4ia9hm9qtcg/Lung.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc1a3209edc17176cf863f6d1801.dl.dropboxusercontent.com/cd/0/get/BOBy4jGTm-xPo4quQoQv-E4EQJfMTbQNiJ_rd9w2RLmvFb9xorAX5szWFICJZRX86tDxeNke846zwBnr2wzCjIz883tr8l5JoK7-YO7qs_gOuTf7GwFG1eT_wMTXd222cOM-KBhH8MbCA8zXeXZQyQxN/file?dl=1# [following]\n",
      "--2021-05-07 02:36:46--  https://uc1a3209edc17176cf863f6d1801.dl.dropboxusercontent.com/cd/0/get/BOBy4jGTm-xPo4quQoQv-E4EQJfMTbQNiJ_rd9w2RLmvFb9xorAX5szWFICJZRX86tDxeNke846zwBnr2wzCjIz883tr8l5JoK7-YO7qs_gOuTf7GwFG1eT_wMTXd222cOM-KBhH8MbCA8zXeXZQyQxN/file?dl=1\n",
      "Resolving uc1a3209edc17176cf863f6d1801.dl.dropboxusercontent.com (uc1a3209edc17176cf863f6d1801.dl.dropboxusercontent.com)... 162.125.7.15, 2620:100:601a:15::a27d:70f\n",
      "Connecting to uc1a3209edc17176cf863f6d1801.dl.dropboxusercontent.com (uc1a3209edc17176cf863f6d1801.dl.dropboxusercontent.com)|162.125.7.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20787027 (20M) [application/binary]\n",
      "Saving to: ‘data/Lung.tar.gz’\n",
      "\n",
      "data/Lung.tar.gz    100%[===================>]  19.82M  47.6MB/s    in 0.4s    \n",
      "\n",
      "2021-05-07 02:36:47 (47.6 MB/s) - ‘data/Lung.tar.gz’ saved [20787027/20787027]\n",
      "\n",
      "tar: option requires an argument -- 'f'\n",
      "Try 'tar --help' or 'tar --usage' for more information.\n",
      "--2021-05-07 02:36:50--  https://www.dropbox.com/s/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.18, 2620:100:601a:18::a27d:712\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb [following]\n",
      "--2021-05-07 02:36:50--  https://www.dropbox.com/s/dl/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc4af9cd9575e75772518fbc2ecb.dl.dropboxusercontent.com/cd/0/get/BOB3aVYDH0gau9PFEh3ceFQsS8zQuJWwND9vSPjgy3wrvwJZbH_FFegXs-WiWICMvcr-TJ8QaXD5IHyZl4UTsR7RTWj45la37i0qOT51owTAeQ5zg5aT_YuRbCqYlks2DNRlWvCM7qgpZHORI7KdbMdB/file?dl=1# [following]\n",
      "--2021-05-07 02:36:50--  https://uc4af9cd9575e75772518fbc2ecb.dl.dropboxusercontent.com/cd/0/get/BOB3aVYDH0gau9PFEh3ceFQsS8zQuJWwND9vSPjgy3wrvwJZbH_FFegXs-WiWICMvcr-TJ8QaXD5IHyZl4UTsR7RTWj45la37i0qOT51owTAeQ5zg5aT_YuRbCqYlks2DNRlWvCM7qgpZHORI7KdbMdB/file?dl=1\n",
      "Resolving uc4af9cd9575e75772518fbc2ecb.dl.dropboxusercontent.com (uc4af9cd9575e75772518fbc2ecb.dl.dropboxusercontent.com)... 162.125.7.15, 2620:100:601a:15::a27d:70f\n",
      "Connecting to uc4af9cd9575e75772518fbc2ecb.dl.dropboxusercontent.com (uc4af9cd9575e75772518fbc2ecb.dl.dropboxusercontent.com)|162.125.7.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87624137 (84M) [application/binary]\n",
      "Saving to: ‘data/cl.ontology.nlp.emb’\n",
      "\n",
      "data/cl.ontology.nl 100%[===================>]  83.56M  53.5MB/s    in 1.6s    \n",
      "\n",
      "2021-05-07 02:36:52 (53.5 MB/s) - ‘data/cl.ontology.nlp.emb’ saved [87624137/87624137]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we download the necessary data:\n",
    "if tissue == 'Bladder':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388874'\n",
    "  pretrained_url='https://www.dropbox.com/s/rb89y577l6vs2mm/Bladder.tar.gz?dl=1'\n",
    "elif tissue == 'Blood':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388853'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/kyh9nv202n0db65/Blood.tar.gz?dl=1'\n",
    "elif tissue == 'Bone_Marrow':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388841'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/a3r4ddg7o7kua7z/Bone_Marrow.tar.gz?dl=1'\n",
    "elif tissue == 'Kidney':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388838'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/k41r1a346z0tuip/Kidney.tar.gz?dl=1'\n",
    "elif tissue == 'Large_Intestine':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388835'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/jwvpk727hd54byd/Large_Intestine.tar.gz?dl=1'\n",
    "elif tissue == 'Lung':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388832'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/e4al4ia9hm9qtcg/Lung.tar.gz?dl=1'\n",
    "elif tissue == 'Lymph_Node':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388715'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/mbejy9tcbx9e1yv/Lymph_Node.tar.gz?dl=1'\n",
    "elif tissue == 'Pancreas':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388613'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/r3klvr22m6kq143/Pancreas.tar.gz?dl=1'\n",
    "elif tissue == 'Small_Intestine':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388559'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/7eiv2mke70jinzc/Small_Intestine.tar.gz?dl=1'\n",
    "elif tissue == 'Spleen':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388544'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/6j3iwahsjnb8rb3/Spleen.tar.gz?dl=1'\n",
    "elif tissue == 'Thymus':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388505'\n",
    "  pretrained_url='https://www.dropbox.com/s/9k0mneu2wvpiudz/Thymus.tar.gz?dl=1'\n",
    "elif tissue == 'Trachea':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388460'\n",
    "  pretrained_url = 'https://www.dropbox.com/s/57tthfgkl8jtxk6/Trachea.tar.gz?dl=1'\n",
    "elif tissue == 'Vasculature':\n",
    "  refdata_url = 'https://ndownloader.figshare.com/files/27388451'\n",
    "  pretrained_url='https://www.dropbox.com/s/1wt3r871kxjas5o/Vasculature.tar.gz?dl=1'\n",
    "\n",
    "#TODO: save into data folder (will automatically be saved to the folder mounted by user)\n",
    "    \n",
    "# Download reference dataset\n",
    "output_fn = 'TS_{}.h5ad'.format(tissue)\n",
    "!wget -O data/$output_fn $refdata_url\n",
    "\n",
    "# Download pretrained scVI and scANVI models.\n",
    "output_fn = '{}.tar.gz'.format(tissue)\n",
    "output_fn = os.path.join('data', output_fn)\n",
    "!wget -O $output_fn $pretrained_url\n",
    "!tar -xvzf $output_folder\n",
    "\n",
    "# Download onclass files\n",
    "!wget -O data/cl.obo -q https://www.dropbox.com/s/hodp0etapzrd8ak/cl.obo?dl=1 \n",
    "!wget -O data/cl.ontology -q https://www.dropbox.com/s/nes0zprzfbwbgj5/cl.ontology?dl=1\n",
    "!wget -O data/cl.ontology.nlp.emb https://www.dropbox.com/s/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb?dl=1\n",
    "\n",
    "# Download annoation code\n",
    "!wget -O data/annotation.py -q https://www.dropbox.com/s/id8sallwrunjc5c/annotation.py?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: obonet in /opt/conda/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from obonet) (2.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from networkx->obonet) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install obonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is not subset, training offline.\n",
      "Sampling 100 per label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/annotation.py:377: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ref_adata.obs[\"_ref_subsample\"][ref_subsample_idx] = True\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2487: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.\n",
      "  res = method(*args, **kwargs)\n",
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:144: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  df.loc[: int(n_top_genes), 'highly_variable'] = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Using batches from adata.obs\u001b[1m[\u001b[0m\u001b[32m\"_batch_annotation\"\u001b[0m\u001b[1m]\u001b[0m                                   \n",
      "\u001b[34mINFO    \u001b[0m Using labels from adata.obs\u001b[1m[\u001b[0m\u001b[32m\"_labels_annotation\"\u001b[0m\u001b[1m]\u001b[0m                                   \n",
      "\u001b[34mINFO    \u001b[0m Using data from adata.layers\u001b[1m[\u001b[0m\u001b[32m\"scvi_counts\"\u001b[0m\u001b[1m]\u001b[0m                                         \n",
      "\u001b[34mINFO    \u001b[0m Computing library size prior per batch                                              \n",
      "\u001b[34mINFO    \u001b[0m Successfully registered anndata object containing \u001b[1;34m104505\u001b[0m cells, \u001b[1;34m4000\u001b[0m vars, \u001b[1;34m6\u001b[0m        \n",
      "         batches, \u001b[1;34m36\u001b[0m labels, and \u001b[1;34m0\u001b[0m proteins. Also registered \u001b[1;34m0\u001b[0m extra categorical covariates  \n",
      "         and \u001b[1;34m0\u001b[0m extra continuous covariates.                                                  \n",
      "\u001b[34mINFO    \u001b[0m Please do not further modify adata until model is trained.                          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_id' as categorical\n",
      "... storing 'method' as categorical\n",
      "... storing 'donor' as categorical\n",
      "... storing 'cell_ontology_type' as categorical\n",
      "... storing 'donor_method' as categorical\n",
      "... storing 'cell_ontology_id' as categorical\n",
      "... storing '_batch_annotation' as categorical\n",
      "... storing '_dataset' as categorical\n",
      "... storing 'final_annotation_cell_ontology_id' as categorical\n",
      "... storing '_labels_annotation' as categorical\n",
      "... storing 'Annotation' as categorical\n",
      "... storing 'Manually Annotated' as categorical\n",
      "... storing 'Donor' as categorical\n",
      "... storing 'Method' as categorical\n",
      "... storing 'Organ' as categorical\n",
      "... storing 'Compartment' as categorical\n",
      "... storing 'Anatomical Information' as categorical\n",
      "... storing '_batch' as categorical\n",
      "... storing '_batch_annotation' as categorical\n",
      "... storing '_dataset' as categorical\n",
      "... storing 'final_annotation_cell_ontology_id' as categorical\n",
      "... storing '_labels_annotation' as categorical\n"
     ]
    }
   ],
   "source": [
    "# here we setup the query dataset with the reference dataset\n",
    "import annotation\n",
    "import importlib\n",
    "import os\n",
    "importlib.reload(annotation)\n",
    "from annotation import process_query\n",
    "\n",
    "# Following parameters are specific to Tabula Sapiens dataset\n",
    "ref_labels_key='Annotation'\n",
    "ref_adata_path = 'data/TS_{}.h5ad'.format(tissue)\n",
    "ref_layers_key = 'raw_counts'\n",
    "\n",
    "pretrained_scanvi_path = os.path.join(tissue, tissue + \"_scanvi_model\")\n",
    "pretrained_scvi_path = os.path.join(tissue, tissue + \"_scvi_model\")\n",
    "\n",
    "adata = process_query(query_adata,\n",
    "                      tissue=tissue,\n",
    "                      save_folder=save_folder,\n",
    "                      query_batch_key=query_batch_key,\n",
    "                      query_layers_key=query_layers_key,\n",
    "                      query_labels_key=query_labels_key,\n",
    "                      unknown_celltype_label=unknown_celltype_label,\n",
    "                      pretrained_scvi_path=pretrained_scvi_path,\n",
    "                      ref_labels_key=ref_labels_key, \n",
    "                      ref_layers_key=ref_layers_key,\n",
    "                      training_mode=training_mode,\n",
    "                      ref_adata_path=ref_adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 75071 × 23681\n",
       "    obs: 'cell_id', 'method', 'donor', 'cell_ontology_type', 'donor_method', 'cell_ontology_id', '_batch_annotation', '_dataset', '_ref_subsample', 'final_annotation_cell_ontology_id', '_labels_annotation'\n",
       "    var: 'feature_types.0.0-0', 'n_cells.0.0-0', 'gene_symbol.0.0-0', 'n_cells.1.0-0', 'n_cells.0-0', 'n_cells.1.1-0', 'feature_types.0.0.0.1-0', 'gene_symbol.0.0.0.1-0', 'n_cells.1.0.0.1-0', 'n_cells.1.0.1-0', 'n_cells-0', 'len-0', 'ensembl_id-0', 'contamination_prop-0-0', 'contamination_prop-1-0', 'contamination_prop-10-0', 'contamination_prop-11-0', 'contamination_prop-12-0', 'contamination_prop-13-0', 'contamination_prop-14-0', 'contamination_prop-2-0', 'contamination_prop-3-0', 'contamination_prop-4-0', 'contamination_prop-5-0', 'contamination_prop-6-0', 'contamination_prop-7-0', 'contamination_prop-8-0', 'contamination_prop-9-0'\n",
       "    layers: 'scvi_counts'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bbknn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCwpkupc_cu-"
   },
   "source": [
    "# Step 5: Run Automated Cell Annotation Methods\n",
    "No user action required. Takes about 30 minutes to run. \n",
    "\n",
    "Your results will be saved to the folder you provided as **save_folder**.\n",
    "\n",
    "There will be the following files:\n",
    "- `annotated_query.h5ad` containing annotated query cells. The consensus annotations will be in `consensus_prediction`. There will also be a `consensus_percentage` field which is the percentage of methods that had the same prediction. \n",
    "- `annotated_query_plus_ref.h5ad` containing your query and the reference cells with predicted annotations. \n",
    "- `confusion_matrices.pdf` which contains the confusion matrices between the consensus_predictions and each individual method.\n",
    "- `csv` files containing the metrics for each confusion matrix. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTAKzgPI69v6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrating data with bbknn.\n",
      "Classifying with knn on bbknn distances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/neighbors/_base.py:175: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn('Precomputed sparse input was not sorted by data.',\n",
      "/home/jovyan/work/annotation.py:703: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adata.obs[result_key][query_idx] = knn_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved knn on bbknn results to adata.obs[\"knn_on_bbknn_pred\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'knn_on_bbknn_pred' as categorical\n",
      "... storing 'knn_on_bbknn_pred' as categorical\n",
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scVI.\n",
      "Training scvi offline.\n",
      "Epoch 1/77:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import annotation\n",
    "importlib.reload(annotation)\n",
    "from annotation import annotate_data\n",
    "\n",
    "annotate_data(adata,\n",
    "              methods, \n",
    "              save_folder,\n",
    "              pretrained_scvi_path=pretrained_scvi_path,\n",
    "              pretrained_scanvi_path=pretrained_scanvi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUsopmFr7Cw0"
   },
   "source": [
    "# Step 6 Generate Statistics and Figures\n",
    "No user action required.\n",
    "\n",
    "## Agreements\n",
    "First we define some variables from the results files to make the code cleaner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting bbknn\n",
      "  Downloading bbknn-1.4.1-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from bbknn) (0.24.1)\n",
      "Requirement already satisfied: umap-learn in /opt/conda/lib/python3.8/site-packages (from bbknn) (0.5.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from bbknn) (1.6.1)\n",
      "Collecting Cython\n",
      "  Downloading Cython-0.29.23-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bbknn) (20.9)\n",
      "Requirement already satisfied: annoy in /opt/conda/lib/python3.8/site-packages (from bbknn) (1.17.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from bbknn) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bbknn) (2.4.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->bbknn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->bbknn) (1.0.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.8/site-packages (from umap-learn->bbknn) (0.5.2)\n",
      "Requirement already satisfied: numba>=0.49 in /opt/conda/lib/python3.8/site-packages (from umap-learn->bbknn) (0.52.0)\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /opt/conda/lib/python3.8/site-packages (from numba>=0.49->umap-learn->bbknn) (0.35.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba>=0.49->umap-learn->bbknn) (49.6.0.post20210108)\n",
      "Installing collected packages: Cython, bbknn\n",
      "Successfully installed Cython-0.29.23 bbknn-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bbknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FSlWKiqHI0Z",
    "outputId": "20f832f7-78f6-46ac-f27f-576ea4efe25f"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'consensus_prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4e994eb09634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mis_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsensus_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mis_query\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mis_query\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels_annotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcelltypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'consensus_prediction'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_file = os.path.join(save_folder,'annotated_query_plus_ref.h5ad')\n",
    "results = anndata.read(results_file)\n",
    "is_query = results.obs._dataset == \"query\"\n",
    "methods = [x for x in results.obs.columns if x.endswith(\"_pred\")]\n",
    "labels = results.obs.consensus_prediction.astype(str)\n",
    "labels[~is_query] = results[~is_query].obs._labels_annotation.astype(str)\n",
    "celltypes = np.unique(labels)\n",
    "latent_methods = results.obsm.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of consensus percentage\n",
    "The more the algorithms agree with each other, the better the annotation has worked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKrQqa_PsDSl",
    "outputId": "c18b0a6f-bef9-46cc-f40d-246d657372d4"
   },
   "outputs": [],
   "source": [
    "agreement_counts = pd.DataFrame(\n",
    "    np.unique(results[is_query].obs[\"consensus_percentage\"], return_counts=True)\n",
    ").T\n",
    "\n",
    "agreement_counts.columns = [\"Percent Agreement\", \"Count\"]\n",
    "agreement_counts.plot.bar(\n",
    "    x=\"Percent Agreement\", y=\"Count\", legend=False, figsize=(4, 3)\n",
    ")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Percent of Algorithms Agreeing with Majority Vote\")\n",
    "figpath = os.path.join(save_folder, \"Concensus_Percentage_barplot.pdf\")\n",
    "plt.savefig(figpath, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per cell type agreement\n",
    "Some cell types can be better predicted than others, and we can highlight the celltypes that are poorly predicted by looking at the per celltype agreement. The cell types are separated by the concensus predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgj0BtKYxs2j",
    "outputId": "acdec82c-ef88-4544-e44f-f7415769767d"
   },
   "outputs": [],
   "source": [
    "mean_agreement = [\n",
    "    np.mean(results[is_query & (labels == x)].obs[\"consensus_percentage\"].astype(float))\n",
    "    for x in celltypes\n",
    "]\n",
    "mean_agreement = pd.DataFrame([mean_agreement], index=[\"agreement\"]).T\n",
    "mean_agreement.index = celltypes\n",
    "\n",
    "mean_agreement = mean_agreement.sort_values(\"agreement\", ascending=True)\n",
    "mean_agreement.plot.bar(y=\"agreement\", figsize=(15, 2), legend=False)\n",
    "plt.ylabel(\"Mean Agreement\")\n",
    "plt.xticks(rotation=290, ha=\"left\")\n",
    "figpath = os.path.join(save_folder, \"percelltype_agreement_barplot.pdf\")\n",
    "plt.savefig(figpath, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell type proportion plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9A5nAa9xvPn",
    "outputId": "76f47aa9-8462-4693-f5b5-82139602c311"
   },
   "outputs": [],
   "source": [
    "prop = pd.DataFrame(index=celltypes, columns=[\"ref\", \"query\"])\n",
    "for x in celltypes:\n",
    "    prop.loc[x, \"query\"] = np.sum(labels[is_query] == x)\n",
    "    prop.loc[x, \"ref\"] = np.sum(labels[~is_query] == x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dypOLE3aiLek"
   },
   "outputs": [],
   "source": [
    "prop.loc[mean_agreement.index].plot(kind='bar', figsize=(len(celltypes)*0.5,4),logy=True)\n",
    "plt.legend(bbox_to_anchor=(1, 0.9))\n",
    "plt.ylabel('log Celltype Abundance')\n",
    "plt.tight_layout()\n",
    "figpath = os.path.join(save_folder, 'celltype_prop_barplot.pdf')\n",
    "plt.savefig(figpath, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Automated Cell Annotation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
