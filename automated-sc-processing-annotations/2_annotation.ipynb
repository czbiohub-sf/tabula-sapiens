{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import scanpy as sc\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "# Import OnClass related libs\n",
    "from OnClass.utils import *\n",
    "from OnClass.OnClassModel import OnClassModel\n",
    "from OnClass.other_datasets_utils import my_assemble, data_names_all, load_names\n",
    "\n",
    "# Import svm related libs\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Import scVI related libs\n",
    "from scvi.inference import UnsupervisedTrainer, SemiSupervisedTrainer\n",
    "from scvi.dataset import AnnDatasetFromAnnData\n",
    "from scvi.models import VAE, SCANVI\n",
    "import torch\n",
    "\n",
    "def balance_n_labelled(l, labelled, nlabels=30):\n",
    "    balanced_labelled = []\n",
    "    for i in np.unique(l[labelled]):\n",
    "        idx = np.where(l == i)[0]\n",
    "        if len(idx) >= nlabels:\n",
    "            subset = np.random.choice(idx, nlabels, replace=False)\n",
    "        else:\n",
    "            subset = idx\n",
    "        balanced_labelled.append(subset)\n",
    "    balanced_labelled = np.concatenate(balanced_labelled)\n",
    "    return balanced_labelled\n",
    "\n",
    "# Import singlecellnet related libs\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as ro\n",
    "# import pandas.rpy.common as com\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "dplyr = importr('dplyr')\n",
    "singleCellNet = importr('singleCellNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = '/content/data/adata_small_test.h5ad'\n",
    "output_file_path = '/content/data/adata_small_test_output.h5ad'\n",
    "data_file = '/content/data/OnClass_data/data_used_for_training/tabula-muris-senis-facs_cell_ontology.h5ad'\n",
    "# data_file = '/content/Pilot1_Pilot2.Final.Small_Intestine.h5ad'\n",
    "cell_type_network_file='/content/data/OnClass_data/OnClass_data_others/cell_ontology/cl.ontology'\n",
    "use_pretrain_emb= '/content/data/OnClass_data/pretrain/tp2emb_500'\n",
    "name_mapping_file= '/content/data/OnClass_data/cell_ontology/cl.obo'\n",
    "use_pretrain_data= '/content/data/OnClass_data/pretrain/BilinearNN_50019'\n",
    "use_pretrain_data_expression= '/content/data/OnClass_data/pretrain/BilinearNN_500'\n",
    "annotation_method = 'onclass'\n",
    "AnnData_label = 'cell_ontology_class_reannotated'\n",
    "AnnData_label = 'cell_ontology_class'\n",
    "AnnData_batch= 'batch'\n",
    "use_cuda = False\n",
    "scvi_model=None\n",
    "scanvi_model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_method = 'scanvi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if annotation_method == 'onclass':\n",
    "    print('Embed the cell ontology')\n",
    "\n",
    "    onclassmodel = OnClassModel()\n",
    "    tp2emb, tp2i, i2tp = onclassmodel.EmbedCellTypes(dim=500,\n",
    "        cell_type_network_file=cell_type_network_file,#'../data/OnClass_data/OnClass_data_others/cell_ontology/cl.ontology',\n",
    "        use_pretrain=use_pretrain_emb)#'../data/OnClass_data/pretrain/tp2emb_500')\n",
    "\n",
    "    print('Here, we used the pretrain cell type embedding file tp2emb_500')\n",
    "\n",
    "    data_file = data_file#'../data/OnClass_data/data_used_for_training/tabula-muris-senis-facs_cell_ontology.h5ad' #same as the input\n",
    "    train_X, train_genes, train_Y = read_data(feature_file=data_file, tp2i = tp2i, AnnData_label=AnnData_label)\n",
    "\n",
    "    print('Load the new dataset.')#Scanorama is used autoamtically to correct batch effcts.:\n",
    "    test_data_file = input_file_path #'../data/output/output_processed.h5ad'\n",
    "    test_X, test_genes, test_Y, test_AnnData = read_data(feature_file=test_data_file, tp2i = tp2i, return_AnnData=True, AnnData_label='cell_ontology_id')\n",
    "\n",
    "    print('Predict the labels of cells')# in droplet cells. Scanorama is used autoamtically to correct batch effcts.:\n",
    "    # currently only running on tensor flow 1; working on the fix for tensor flow 2\n",
    "    # currently only running with correct_batch=False\n",
    "    onclassmodel.train(train_X, train_Y, tp2emb, train_genes, nhidden=[500], log_transform = True, use_pretrain = use_pretrain_data, pretrain_expression=use_pretrain_data_expression)\n",
    "\n",
    "\n",
    "    test_label = onclassmodel.predict(test_X, test_genes,log_transform=True,correct_batch=False)\n",
    "\n",
    "    # Add the new annotations to the working file\n",
    "    x = write_anndata_data(test_label, test_AnnData, i2tp, name_mapping_file=name_mapping_file)#'../data/OnClass_data/cell_ontology/cl.obo')#output_file is optional\n",
    "\n",
    "    #print (x.obs['OnClass_annotation_ontology_ID'])\n",
    "    #print (x.obs['OnClass_annotation_ontology_name'])\n",
    "\n",
    "    x.write(output_file_path)#('../data/output/output_processed_annotated.h5ad')\n",
    "    # Launch cellxgene with experimental_annotations\n",
    "elif annotation_method=='scanvi':\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    print('data preprocessing')\n",
    "    train_data = sc.read_h5ad(data_file)\n",
    "    test_data = sc.read_h5ad(input_file_path)\n",
    "    data = train_data.concatenate(test_data)\n",
    "\n",
    "    batch = list(np.unique(data.obs[AnnData_batch]))\n",
    "    batch_id = [batch.index(x) for x in data.obs[AnnData_batch]]\n",
    "    data.obs['batch'] = batch_id\n",
    "\n",
    "    scvi_data = AnnDatasetFromAnnData(data, batch_label = 'batch')\n",
    "    labels = data.obs[AnnData_label]\n",
    "    scvi_data.cell_types = labels.astype('category').unique()\n",
    "    scvi_data.labels = np.unique(labels.astype('category').cat.codes, return_inverse=True)[1]\n",
    "    scvi_data.labels = scvi_data.labels.reshape(len(scvi_data.labels), 1)\n",
    "    scvi_data.n_labels = len(scvi_data.cell_types)\n",
    "\n",
    "    vae = VAE(scvi_data.nb_genes, n_batch=scvi_data.n_batches,\n",
    "              n_layers=3, n_latent=50, dispersion='gene-batch',\n",
    "              reconstruction_loss='zinb')\n",
    "    trainer = UnsupervisedTrainer(\n",
    "        vae,\n",
    "        scvi_data,\n",
    "        train_size=0.99,\n",
    "        use_cuda=use_cuda,\n",
    "        frequency=5,\n",
    "        data_loader_kwargs={\"pin_memory\": False},\n",
    "        n_epochs_kl_warmup=10\n",
    "    )\n",
    "    if os.path.isfile(scvi_model):\n",
    "        print('loading pre-trained scVI model')\n",
    "        trainer.model.load_state_dict(torch.load(scvi_model))\n",
    "        trainer.model.eval()\n",
    "    else:\n",
    "        print('train scVI')\n",
    "        trainer.train(n_epochs=1)\n",
    "        torch.save(trainer.model.state_dict(), scvi_model)\n",
    "\n",
    "    if 'unassigned' in scvi_data.cell_types:\n",
    "        unlabelled_idx = list(scvi_data.cell_types).index('unassigned')\n",
    "        labelled = np.where(scvi_data.labels.ravel() != unlabelled_idx)[0]\n",
    "    else:\n",
    "        labelled = np.arange(len(scvi_data.labels))\n",
    "\n",
    "        # balance number of labelled cells from each cell type\n",
    "    labelled = balance_n_labelled(scvi_data.labels.ravel(), labelled, nlabels=50)\n",
    "    labelled = np.random.choice(labelled, len(labelled), replace=False)\n",
    "\n",
    "    unlabelled = [x for x in np.arange(len(scvi_data.labels.ravel())) if x not in labelled]\n",
    "    unlabelled = np.random.choice(unlabelled, len(unlabelled), replace=False)\n",
    "\n",
    "    scanvi = SCANVI(scvi_data.nb_genes, scvi_data.n_batches, scvi_data.n_labels, n_layers=3, n_latent=50,\n",
    "                    symmetric_kl=True, dispersion='gene-batch')\n",
    "\n",
    "\n",
    "    trainer_scanvi = SemiSupervisedTrainer(scanvi, scvi_data,\n",
    "                                            n_epochs_classifier=100,\n",
    "                                            lr_classification=5 * 1e-3, seed=1,\n",
    "                                            n_epochs_kl_warmup=1)\n",
    "\n",
    "    trainer_scanvi.model.load_state_dict(torch.load(scvi_model), strict=False)\n",
    "    trainer_scanvi.model.eval()\n",
    "    trainer_scanvi.labelled_set = trainer_scanvi.create_posterior(indices=labelled)\n",
    "    trainer_scanvi.unlabelled_set = trainer_scanvi.create_posterior(indices=unlabelled)\n",
    "\n",
    "    if os.path.isfile(scanvi_model):\n",
    "        trainer_scanvi.model.load_state_dict(torch.load(scanvi_model))\n",
    "        trainer_scanvi.model.eval()\n",
    "    else:\n",
    "        trainer_scanvi.train(n_epochs=15)\n",
    "        torch.save(trainer_scanvi.model.state_dict(), scanvi_model)\n",
    "\n",
    "    full = trainer_scanvi.create_posterior(trainer_scanvi.model, data, indices=np.arange(len(data)))\n",
    "    _, pred = full.sequential().compute_predictions()\n",
    "    data.obs['scanvi_pred'] = pred\n",
    "    data = data[train_data.obs.index]\n",
    "    data.write(output_file_path + \"scanvi.h5ad\")\n",
    "\n",
    "elif annotation_method=='svm':\n",
    "    train_data = sc.read_h5ad(data_file)\n",
    "    test_data = sc.read_h5ad(input_file_path)\n",
    "    data = train_data.concatenate(test_data)\n",
    "    # AnnData_batch must be a column that exist in both the data file and test data file\n",
    "    batch = list(np.unique(data.obs[AnnData_batch]))\n",
    "    batch_id = [batch.index(x) for x in data.obs[AnnData_batch]]\n",
    "    data.obs['batch'] = batch_id\n",
    "\n",
    "    data = np.log1p(data.X)\n",
    "    # feature selection\n",
    "    sc.pp.highly_variable_genes(data, min_mean=0.0125, max_mean=3, min_disp=0.5, batch_key='batch')\n",
    "    var_select = data.var.highly_variable_nbatches > 1\n",
    "    var_genes = var_select.index[var_select]\n",
    "    data = data[:, var_genes]\n",
    "\n",
    "    train_idx = train_data.obs.index\n",
    "    test_idx = test_data.obs.index\n",
    "    train_X = data[train_idx].X\n",
    "    test_X = data[test_idx].X\n",
    "    train_Y = data[train_idx].obs[AnnData_label]\n",
    "\n",
    "    # train model\n",
    "    Classifier = LinearSVC()\n",
    "    Classifier.fit(train_X, train_Y)\n",
    "    pred = Classifier.predict(test_X)\n",
    "    train_data.obs['SVM_pred'] = pred\n",
    "    train_data.write(output_file_path + \"SVM.h5ad\")\n",
    "\n",
    "elif annotation_method=='singlecellnet':\n",
    "    print('running singlecellnet')\n",
    "\n",
    "    train_data = sc.read_h5ad(data_file)\n",
    "    test_data = sc.read_h5ad(input_file_path)\n",
    "    data = train_data.concatenate(test_data)\n",
    "    # AnnData_batch must be a column that exist in both the data file and test data file\n",
    "    batch = list(np.unique(data.obs[AnnData_batch]))\n",
    "    batch_id = [batch.index(x) for x in data.obs[AnnData_batch]]\n",
    "    data.obs['batch'] = batch_id\n",
    "\n",
    "    data = np.log1p(data.X)\n",
    "    # # feature selection\n",
    "    # sc.pp.highly_variable_genes(data, min_mean=0.0125, max_mean=3, min_disp=0.5, batch_key='batch')\n",
    "    # var_select = data.var.highly_variable_nbatches > 1\n",
    "    # var_genes = var_select.index[var_select]\n",
    "    # data = data[:, var_genes]\n",
    "\n",
    "    train_idx = train_data.obs.index\n",
    "    test_idx = test_data.obs.index\n",
    "    train_X = data[train_idx].X\n",
    "    train_Y = data[train_idx].obs\n",
    "\n",
    "    R_train_X = ro.r.matrix(train_X)\n",
    "    R_train_Y = com.convert_to_r_dataframe(train_Y)\n",
    "\n",
    "    cgenes2 = singleCellNet.findClassyGenes(R_train_X, R_train_Y, AnnData_label)\n",
    "    # ro.globalenv['cgenesA'] = cgenes2.rx2('cgenes')\n",
    "    cgenes = cgenes2.rx2('cgenes')\n",
    "\n",
    "    train_X = data[train_idx,cgenes].X\n",
    "    R_train_X = ro.r.matrix(train_X)\n",
    "\n",
    "    xpairs = singleCellNet.ptGetTop(R_train_X, cgenes2.rx2('grps'), cgenes2.rx2('cgenes_list'))\n",
    "    pdTrain = singleCellNet.query_transform(R_train_X, xpairs)\n",
    "\n",
    "    rf = singleCellNet.sc_makeClassifier(pdTrain.rx(xpairs,True), genes=xpairs, groups= cgenes2.rx2('grps'))\n",
    "\n",
    "    test_X = data[test_idx,cgenes].X\n",
    "    R_test_X = ro.r.matrix(test_X)\n",
    "    DataTest = singleCellNet.query_transform(R_test_X, xpairs)\n",
    "    classRes = singleCellNet.rf_classPredict(rf, DataTest)\n",
    "    pred = com.load_data(classRes)\n",
    "\n",
    "    train_data.obsm['singlecellnet'] = pred\n",
    "    train_data.write(output_file_path + \"singlecellnet.h5ad\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabula_sapiens",
   "language": "python",
   "name": "tabula_sapiens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
